# Final-Project-Statistical-Modelling-with-Python

## Project/Goals
The goals of this project are to:
    1 - Be comfortable getting information from API
    2 - Deal with the challenge of parsing Json file
    3 - Improve the skill to identify relevant information
    4 - Browse the data to find relevent patterns

## Process
### (your step 1)
### (your step 2)
Step 1: Getting the data from API

Step 2: Parse the response to get the relevant information

Step 3: Join the collected data

Step 4: Perform EDA to validate yout data

Step 5: Analyze patterns 

## Results
1 - Yelp has a greater coverage than Four Square
2 - Yelp returns more consitent response
3 - In term of IDs assigned to the stations, Yelp is more reliable in returning them in a response.

## Challenges 
1 - Find a key to join the data. The (latitude, longitude) appears to be logically a good key, but the servers do not all return the same exact values for them. It differs from servers and will require delicate attention to handle.

2 - Find the right city that will return relevant data from the servers. For instance, a city can drive useful data from CityBikes but the stations inside has a poor coverage by Four Square and Yelp.

3 - Handling this amount of data

## Future Goals
1 - Dig dipper on the coverage diffence between Four Square and Yelp. For instance, is it due to the fact that Four Square target his coverage. Try to find patterns in his coverage policy.

2 - Analyze if there is a background relationship that causes the latitude and longitude distributions to approach normal distribution.


